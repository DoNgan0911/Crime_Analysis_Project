---
title: "DTSC 3010 Section 020 Final Project"
output:
  pdf_document: default
  html_document:
    df_print: paged
author: "Do Ngan"
date: "2024-10-12"

    
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
  My research question:
  **What are the key patterns in crime occurrences, and How can we predict crime types and identify whether crime reports are timely or delayed based on demographic factors, location, and times? **


# Read data
```{r cars}
final_crime_data <- read.csv("D:/R Project/new_crime_data.csv")
summary(final_crime_data)
ncol(final_crime_data)
```
# 4.1. Understand the target variable
**Summary and Visualize the frequency of each crime type**
```{r}
summary(final_crime_data$Crm.Cd.Desc)
library("ggplot2")
ggplot(final_crime_data ,aes(x =  Crm.Cd.Desc))+
  geom_bar( fill= "pink")+
  labs(title = "Crime types", x = "Crime Desc", y ="Frequency")
```
 Crime Type has 3 different levels: Battery - Simple Assault, Burglary from Vehicle, Theft of identity.



# 4.2. Understand categorical variables
**Victim Sex**
```{r}
table(final_crime_data$Crm.Cd.Desc, final_crime_data$Vict.Sex)
chisq.test(table(final_crime_data$Crm.Cd.Desc, final_crime_data$Vict.Sex))
```
 The p-value is extremely small, indicating that the result is highly statistically significant => reject null hypothesis that Crm.Cd.Desc and Vict.Sex are independent.



```{r}
library(ggplot2)
ggplot(final_crime_data, aes(x = Crm.Cd.Desc, fill = Vict.Sex)) +
  geom_bar( position = "fill" ) +
  labs(y = 'Proportion', x = 'Crime Type')
```
 
 General observation shows that the crime types occurs is quite balanced between Male and Female.
 
 
 
**AREA.NAME**
```{r}
library("dplyr")
area_name_counts <- final_crime_data %>% group_by(AREA.NAME) %>% 
  summarise(count = n()) %>% arrange(desc(count))
head(area_name_counts)
```
 Central areas has the highest rate in Crime type in the dataset.



**Premis Code**
```{r}
chisq.test(table(final_crime_data$Crm.Cd.Desc, final_crime_data$Premis.Cd),
           simulate.p.value = TRUE, B = 10000)

```

 The p-value is extremely small, indicating that the result is highly statistically significant => reject null hypothesis that Crm.Cd.Desc and Premis.Cd are independent.



**Victim Descent**
```{r}
#The frequency of victim Descent
vict_descent_counts <- final_crime_data %>% group_by(Vict.Descent) %>% 
  summarise(count = n()) %>% arrange(desc(count))
vict_descent_counts
```
 H (Hispanic/Latin/Mexican) occupies the highest in victims' rates 
 
**Time_Slots_Happening**
```{r}
time_slot_trend <- final_crime_data %>% group_by(Time_Slots_Happening) %>%
  summarise(count = n())
ggplot(time_slot_trend, aes(x = Time_Slots_Happening, y = count))+
  geom_bar(stat = "identity", fill = "steelblue", alpha = 0.7)

```
  Crimes often occurs in the afternoon (12PM - 18:59PM) compared to others periods of the day. This indicates that preventive solutions during the afternoon can be effective in addressing crimes.
  
# 4.3. Understand continuous variables
**Victim Age**
```{r}
ggplot(final_crime_data, aes(x = Vict.Age)) +
  geom_density(fill = 'blue', alpha = 0.5) +
  labs(title = 'Density plot', x = 'Vict.Age', y = 'density')+
  scale_x_continuous(breaks = seq(0, max(final_crime_data$Vict.Age), by = 10))

```
 Age group between 25 and 35 has the most victims. After that, the density decrease, showing fewer victims in older age groups => The 25 - 35 age group could be related to crime occurrences due to higher activity levels outside such as work, commuting,... The older group may spend more time in private space at home, reducing exposuring crime.



```{r}
ggplot(data = final_crime_data) + 
  geom_smooth(mapping = aes(x = Vict.Age, y = Crm.Cd))

```

 A noticeable focus of crime occurs around age 10, and Crm.Cd 624 (Battery-Simple Assault) => This crime type is more common among younger victims, it can be related to conflicts in academic environment or peer conflicts.



# 4.4 t-test vs ANOVA-test

**t-test: Check the average age of Victims differs significantly between weekends and weekdays?**
```{r}
Age_in_Weekends <- final_crime_data %>% filter(Weekdays_of_DateOcc == 'Saturday'
                                               | Weekdays_of_DateOcc == 'Sunday' ) %>%
  select(Vict.Age)
Age_in_Weekdays <- final_crime_data %>% filter(Weekdays_of_DateOcc != 'Saturday'
                                               & Weekdays_of_DateOcc != 'Sunday' ) %>%
  select(Vict.Age)
t.test(Age_in_Weekends, Age_in_Weekdays)
```
 The p-value is smaller than 0.05, indicating that victim age differs between weekends and weekdays. On weekends, victims tend to be younger slightly, reflecting differences in activities, social hours. On weekdays, older victims may be involved in crime occurrences, possibly because of working.



**ANOVA-test: comparing time_to_report across  different area**
```{r}

TimeReport_aov <- aov(Time.to.reports ~ AREA.NAME, data = final_crime_data )
summary(TimeReport_aov)

Average_TimeReport_Areas <- final_crime_data %>% 
  group_by(AREA.NAME) %>% 
  summarise(Average_Time = mean(Time.to.reports, na.rm = TRUE))%>%
  arrange(desc(Average_Time))
head(Average_TimeReport_Areas)

```
 The ANOVA test result and data of average time of report show the difference between areas in reporting crime occurrences.Devonshire has the highest average reporting time, indicating the challenges in this area might be slower police response or residents taking longer time to report crimes. N Hollywood area has the shorter average time in reporting, indicating this area might have better infrastructure to facilitate quickly reports.



# 5.1 Splitting data into train (75%) and test (25%) data
```{r}
library("tidymodels")
library("rpart")
library("rpart.plot")

final_crime_data$Crm.Cd.Desc <- as.factor(final_crime_data$Crm.Cd.Desc)

set.seed(42)
bound <- floor(nrow(final_crime_data) / 4 * 3)
shuffled_crime_data <- final_crime_data[sample(nrow(final_crime_data)),]
train <- shuffled_crime_data[1:bound,]
test <- shuffled_crime_data[(bound+1):nrow(shuffled_crime_data),]
summary(train)
summary(test)
```

# 5.2. Classify crime types based on Victim demographics and crime locations (Comparing performance of models: Decision tree, random forest, SVM)

**SVM and its performance**
```{r}
# Creating model and training model
library("e1071")
classifier <- svm(Crm.Cd.Desc ~ Vict.Descent + Vict.Age + Vict.Sex +
                    AREA.NAME  +Time_Slots_Happening + Weekdays_of_DateOcc + Premis.Cd, 
                  data = train, type = "C-classification", kernel = "radial")
summary(classifier)
#Create predicted column in the test data
test$test_pred_svm <- predict(classifier, test)
#Confusion matrix
conf_mat(test, truth=Crm.Cd.Desc, estimate = test_pred_svm)
#get summary metrics
dt_metrics <- metric_set(accuracy, sens, spec, f_meas, kap)
dt_metrics(test, truth = Crm.Cd.Desc, estimate = test_pred_svm)
```

 Accuracy of 62% indicates the model predicts correctly the crime types about 62% of the time.
 Sensitivity of 62% indicates the model captures around 62% of the actual crime types across all categories.
 Specificity of 81% indicates the model does a good job in identifying correctly non crime types. It s higher than the sensitivity, showing that the model does better in identifying when there is not a crime happening rather than when it is. 
 f_meas of ~59% indicates the balance of precision and recall, indicating the model is doing fairly well but still has room for improvement.
 kap of ~44% means a moderate level of agreement between the actual values and the model prediction
 
 
 
**Decision tree and its performance**
```{r}
tree <- decision_tree() %>% set_engine("rpart") %>% set_mode("classification")
#create recipe
df_recipe <- recipe(Crm.Cd.Desc ~ Vict.Descent + Vict.Age + Vict.Sex +AREA.NAME+
                      Time_Slots_Happening + Weekdays_of_DateOcc + Premis.Cd, 
                    data = train) %>% step_normalize((all_numeric()))
#create decision tree workflow
tree_wf <- workflow() %>% add_recipe(df_recipe) %>% add_model(tree) %>% fit(train)
predResults <- data.frame(predict(tree_wf, test))
#Create predicted column in the test data
colnames(predResults) <- c("test_pred_tree")
test <- cbind(test, predResults)
conf_mat(test, truth=Crm.Cd.Desc, estimate = test_pred_tree)
#get summary metrics
library(yardstick)
dt_metricsS <- metric_set(accuracy, sens, spec, f_meas, kap)
dt_metricsS(test, truth = Crm.Cd.Desc, estimate = test_pred_tree)
```
  Accuracy of 67.7% indicates the model predicts correctly the crime types about 67.7% of the time.
  Sensitivity of 67.6% indicates the model captures around 67.6% of the actual crime types across all categories.
  Specificity of 83.8% indicates the model does a good job in identifying correctly non crime types. It s higher than the sensitivity, showing that the model does better in identifying when there is not a crime happening rather than when it is. 
  f_meas of 65% indicates the balance of precision and recall, indicating the model is doing fairly well but still has room for improvement.
  kap of 51.5% means a moderate level of agreement between the actual values and the model prediction

**Random Forest and its performance**
```{r}
rf <- rand_forest() %>% set_engine("ranger", importance = "impurity") %>%
set_mode("classification")

df_recipe <- recipe(Crm.Cd.Desc ~ Vict.Descent + Vict.Age + Vict.Sex +AREA.NAME+
                      Time_Slots_Happening + Weekdays_of_DateOcc + Premis.Cd, 
                    data = train) %>% step_normalize((all_numeric()))

random_wf_52 <- workflow() %>% add_recipe(df_recipe) %>% add_model(rf) %>% fit(train)

summary(random_wf_52)
#Creating new column test_pred_rf containing predicted values about Crm.Cd.Desc on test data
predResults <- data.frame(predict(random_wf_52,test))
#Create predicted column in the test data
colnames(predResults) <- c("test_pred_rf")
test <- cbind(test, predResults)
#Confusion matrix
conf_mat(test, truth=Crm.Cd.Desc, estimate = test_pred_rf)
#get summary metrics
library(yardstick)
dt_metricsS <- metric_set(accuracy, sens, spec, f_meas, kap)
dt_metricsS(test, truth = Crm.Cd.Desc, estimate = test_pred_rf)
```
 Three classification models was used to predict crime types. I created the confusion matrix and evaluation metrics to gain details about how well the model performed.
 Random Forest Model has the best performance than SVM, Decision tree models in almost key metrics: higher accuracy(nearly 72%), better sensitivity, Superior Specificity, Improved F-measure, and stronger Kappa Score. Especially, the higher in accurancy make Random Forest a stronger option to classify Crime Type based on Victim Demographic and Crime Locations, Time. However, with Random Forest, nearly 28% of predictions predicted incorrectly, so there is still room for improvement to further enhance the performance of this model.

**Tunning hyperparameter Search for Random Forest model**
```{r}
library(dplyr)
library(tidymodels)
train$Vict.Descent <- as.factor(train$Vict.Descent)
#Define the model with tunable parameters
new_rf <- rand_forest(
  trees = tune(),
  mtry = tune(),
  min_n = tune()
) %>% set_engine("ranger", importance = "impurity") %>%
set_mode("classification")
new_random_wf <- workflow() %>% add_recipe(df_recipe) %>% add_model(new_rf)
#Cross validation
cv_folds <- vfold_cv(train, v = 5)
#Defining the grid of hyperparameters
rf_grid <-grid_random(
  trees(range = c(1000,2000)), #number of trees
  mtry(range = c(2,4)), #number of variables at each node to split
  min_n(range = c(2,6)), # minimum number data points at each node
  size = 20 # 20 combinations
)
#Tune the model
tune_results <- tune_grid(new_random_wf, resamples = cv_folds, grid = rf_grid, 
                           metrics = metric_set(accuracy, kap),
  control = control_grid(parallel_over = "everything"))
best_params <- select_best(tune_results, metric = "accuracy")
final_rf <- finalize_workflow(new_random_wf, best_params)
final_model <- fit(final_rf, data = train)
test_pred_rf <- predict(final_model, new_data = test) %>% bind_cols(test)
final_metrics <- test_pred_rf %>% metrics(truth = Crm.Cd.Desc, estimate = .pred_class)
print(final_metrics)

```
  
  
# 5.3. Logistic Regression: Classify Time.to.reports as Delayed (>1 day) or Timely (<= 1 day)

```{r}
library(caret)
table(final_crime_data$Delayed_Report)
glm.fit <- glm(Delayed_Report ~ Time_Slots_Happening + Weekdays_of_DateOcc +
                 Vict.Age + Vict.Sex + Vict.Descent + AREA.NAME + Crm.Cd.Desc ,
               data = train, family = binomial)

predictedprob <- predict(glm.fit, newdata = test, type = "response")
head(predictedprob)
newdata <- data.frame(test$Time_Slots_Happening, test$Weekdays_of_DateOcc, 
                      test$Vict.Age, test$Vict.Sex, test$Vict.Descent, 
                      test$AREA.NAME, test$Crm.Cd.Desc ,predictedprob)

glm.pred = factor(ifelse(predictedprob > 0.5, 1 , 0))
test$Delayed_Report <- factor(test$Delayed_Report, levels = c(0, 1))
confusionMatrix(test$Delayed_Report, glm.pred)
```

 The accuracy of nearly 76.1%, showing this model performs reasonably well in distinguishing whether a crime was reported on time or not. And this model performs better at predicting delayed reports than timely reports, which was shown by the higher PPV than NPV.
 The p-value (Acc > NIR) is statistically significant, showing that the performance of this model is meaningful.
 
